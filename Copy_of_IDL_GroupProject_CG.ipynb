{"cells":[{"cell_type":"code","source":["%pip install torch==1.13.1+cu117 torchvision==0.14.1+cu117 torchtext==0.14.1 torchaudio==0.13.1 torchdata==0.5.1 --extra-index-url https://download.pytorch.org/whl/cu117 -q\n","\n","!pip install wandb --quiet\n","!pip install python-Levenshtein -q\n","!git clone --recursive https://github.com/parlance/ctcdecode.git\n","!pip install wget -q\n","%cd ctcdecode\n","!pip install . -q\n","%cd ..\n","\n","!pip install torchsummaryX -q\n","!pip install mne -q"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HN70G7tImwrz","outputId":"f3c5aef7-a746-451d-f7d8-164a0264f440","executionInfo":{"status":"ok","timestamp":1700235060268,"user_tz":300,"elapsed":413614,"user":{"displayName":"Joshua Kosnoff","userId":"04340476596549550774"}}},"id":"HN70G7tImwrz","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 GB\u001b[0m \u001b[31m835.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.3/24.3 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m97.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m248.6/248.6 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.4/169.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCloning into 'ctcdecode'...\n","remote: Enumerating objects: 1102, done.\u001b[K\n","remote: Counting objects: 100% (39/39), done.\u001b[K\n","remote: Compressing objects: 100% (25/25), done.\u001b[K\n","remote: Total 1102 (delta 16), reused 32 (delta 14), pack-reused 1063\u001b[K\n","Receiving objects: 100% (1102/1102), 782.27 KiB | 19.08 MiB/s, done.\n","Resolving deltas: 100% (529/529), done.\n","Submodule 'third_party/ThreadPool' (https://github.com/progschj/ThreadPool.git) registered for path 'third_party/ThreadPool'\n","Submodule 'third_party/kenlm' (https://github.com/kpu/kenlm.git) registered for path 'third_party/kenlm'\n","Cloning into '/content/ctcdecode/third_party/ThreadPool'...\n","remote: Enumerating objects: 82, done.        \n","remote: Counting objects: 100% (26/26), done.        \n","remote: Compressing objects: 100% (9/9), done.        \n","remote: Total 82 (delta 19), reused 17 (delta 17), pack-reused 56        \n","Receiving objects: 100% (82/82), 13.34 KiB | 2.67 MiB/s, done.\n","Resolving deltas: 100% (36/36), done.\n","Cloning into '/content/ctcdecode/third_party/kenlm'...\n","remote: Enumerating objects: 14161, done.        \n","remote: Counting objects: 100% (474/474), done.        \n","remote: Compressing objects: 100% (328/328), done.        \n","remote: Total 14161 (delta 162), reused 406 (delta 132), pack-reused 13687        \n","Receiving objects: 100% (14161/14161), 5.91 MiB | 10.61 MiB/s, done.\n","Resolving deltas: 100% (8042/8042), done.\n","Submodule path 'third_party/ThreadPool': checked out '9a42ec1329f259a5f4881a291db1dcb8f2ad9040'\n","Submodule path 'third_party/kenlm': checked out '35835f1ac4884126458ac89f9bf6dd9ccad561e0'\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n","/content/ctcdecode\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for ctcdecode (setup.py) ... \u001b[?25l\u001b[?25hdone\n","/content\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","execution_count":null,"id":"94c5dbd7","metadata":{"id":"94c5dbd7","outputId":"f23dc7a9-4418-4db6-950a-5d553413ebd5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700235065196,"user_tz":300,"elapsed":4937,"user":{"displayName":"Joshua Kosnoff","userId":"04340476596549550774"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Device:  cuda\n"]}],"source":["#!activate pytorch_cuda\n","import mne\n","\n","import torch\n","import random\n","import numpy as np\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchsummaryX import summary\n","from torch.utils.data import Dataset, DataLoader\n","from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n","\n","# import torchaudio.transforms as tat\n","\n","from sklearn.metrics import accuracy_score\n","import gc\n","\n","import zipfile\n","import pandas as pd\n","from tqdm import tqdm\n","import os\n","import datetime\n","\n","# imports for decoding and distance calculation\n","import ctcdecode\n","import Levenshtein\n","from ctcdecode import CTCBeamDecoder\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","if torch.backends.mps.is_available():\n","    device = \"mps\"\n","elif torch.cuda.is_available():\n","    device = \"cuda\"\n","else:\n","    device = \"cpu\"\n","\n","print(\"Device: \", device)"]},{"cell_type":"code","execution_count":null,"id":"03522879","metadata":{"id":"03522879"},"outputs":[],"source":["CMUdict_ARPAbet = {\n","    \"\" : \" \",\n","    \"[SIL]\": \"-\", \"NG\": \"G\", \"F\" : \"f\", \"M\" : \"m\", \"AE\": \"@\",\n","    \"R\"    : \"r\", \"UW\": \"u\", \"N\" : \"n\", \"IY\": \"i\", \"AW\": \"W\",\n","    \"V\"    : \"v\", \"UH\": \"U\", \"OW\": \"o\", \"AA\": \"a\", \"ER\": \"R\",\n","    \"HH\"   : \"h\", \"Z\" : \"z\", \"K\" : \"k\", \"CH\": \"C\", \"W\" : \"w\",\n","    \"EY\"   : \"e\", \"ZH\": \"Z\", \"T\" : \"t\", \"EH\": \"E\", \"Y\" : \"y\",\n","    \"AH\"   : \"A\", \"B\" : \"b\", \"P\" : \"p\", \"TH\": \"T\", \"DH\": \"D\",\n","    \"AO\"   : \"c\", \"G\" : \"g\", \"L\" : \"l\", \"JH\": \"j\", \"OY\": \"O\",\n","    \"SH\"   : \"S\", \"D\" : \"d\", \"AY\": \"Y\", \"S\" : \"s\", \"IH\": \"I\",\n","    \"[SOS]\": \"[SOS]\", \"[EOS]\": \"[EOS]\"\n","}\n","\n","CMUdict = list(CMUdict_ARPAbet.keys())\n","ARPAbet = list(CMUdict_ARPAbet.values())\n","\n","\n","PHONEMES = CMUdict[:-2]\n","LABELS = ARPAbet[:-2]"]},{"cell_type":"code","source":["from google.colab import drive # Link your drive if you are a colab user\n","drive.mount('/content/drive') # Models in this HW take a long time to get trained and make sure to save it her"],"metadata":{"id":"jybQUlpVjCkX","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d02ba520-da72-4fcc-c95d-a261190dc97f","executionInfo":{"status":"ok","timestamp":1700236399089,"user_tz":300,"elapsed":1333898,"user":{"displayName":"Joshua Kosnoff","userId":"04340476596549550774"}}},"id":"jybQUlpVjCkX","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# Here, we converted each word into a phoneme using the CMUDict\n","# This took a rediculous amount of time. Don't rerun this. Instead, load the\n","# New csv file with phonemes added to it!\n","wannaSpendForeverMakingDataAgain = False\n","\n","if wannaSpendForeverMakingDataAgain:\n","  import pickle\n","\n","  # # Now its time to make the target labels\n","\n","  !pip install cmudict -q\n","\n","  import cmudict\n","\n","  data_csv =pd.read_csv(\"drive/MyDrive/brennan data/AliceChapterOne-EEG-Phonemes.csv\")\n","  word_list = data_csv[\"Word\"].values\n","  phoneme_list = []\n","\n","  for i, word in enumerate(word_list):\n","      if i % 25 == 0:\n","        print(i)\n","      try:\n","        phoneme_list.append(cmudict.dict()[word.lower()][-1])\n","      except:\n","        # There seems to be weird bug with one of the words???\n","        # We will need to delete the corresponding timestamp EEG data,\n","        # so print the index\n","        print(i, word)\n","\n","  with open('drive/MyDrive/brennan data/IDL_project_data_targets.pkl', 'wb') as fid:\n","      pickle.dump(phoneme_list, fid)"],"metadata":{"id":"AFKcnfNihcq7"},"id":"AFKcnfNihcq7","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load in the new and glorious Phoneme-added dataframe\n","import pandas as pd\n","data_csv =pd.read_csv(\"drive/MyDrive/brennan data/AliceChapterOne-EEG-Phonemes.csv\")\n","data_csv.head()"],"metadata":{"id":"pHYLRN_f3pS2","colab":{"base_uri":"https://localhost:8080/","height":201},"outputId":"d6ab2bb1-58f4-436e-bf95-d9fc0c46541d","executionInfo":{"status":"ok","timestamp":1700237362972,"user_tz":300,"elapsed":2118,"user":{"displayName":"Joshua Kosnoff","userId":"04340476596549550774"}}},"id":"pHYLRN_f3pS2","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Unnamed: 0       Word  Segment     onset    offset  Order  LogFreq  \\\n","0           0      Alice        1  0.046000  0.608721      1     8.65   \n","1           1        was        1  0.562721  0.830543      2    14.56   \n","2           2  beginning        1  0.784543  1.302929      3    10.69   \n","3           3         to        1  1.256929  1.398925      4    16.35   \n","4           4        get        1  1.352925  1.662327      5    13.79   \n","\n","   LogFreq_Prev  LogFreq_Next      SndPower    Length  Position  Sentence  \\\n","0          0.00         14.56  3.620000e-07  0.562721         1         1   \n","1          8.65         10.69  3.840000e-09  0.267822         2         1   \n","2         14.56         16.35  3.690000e-09  0.518386         3         1   \n","3         10.69         13.79  3.970000e-09  0.141996         4         1   \n","4         16.35         13.28  3.770000e-09  0.309402         5         1   \n","\n","   IsLexical     NGRAM       RNN       CFG  \\\n","0        1.0  3.226499  3.126175  2.312348   \n","1        0.0  0.905229  1.691128  1.357460   \n","2        1.0  4.446766  4.100771  5.626722   \n","3        0.0  2.537495  3.833313  5.939201   \n","4        0.0  1.023137  1.013076  2.697304   \n","\n","                                     phonemes  \n","0                    ['AE1', 'L', 'IH0', 'S']  \n","1                           ['W', 'AH0', 'Z']  \n","2  ['B', 'IH0', 'G', 'IH1', 'N', 'IH0', 'NG']  \n","3                                ['T', 'AH0']  \n","4                           ['G', 'IH1', 'T']  "],"text/html":["\n","  <div id=\"df-c3352378-c8ca-4b71-b13b-d50e17b4e9a0\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>Word</th>\n","      <th>Segment</th>\n","      <th>onset</th>\n","      <th>offset</th>\n","      <th>Order</th>\n","      <th>LogFreq</th>\n","      <th>LogFreq_Prev</th>\n","      <th>LogFreq_Next</th>\n","      <th>SndPower</th>\n","      <th>Length</th>\n","      <th>Position</th>\n","      <th>Sentence</th>\n","      <th>IsLexical</th>\n","      <th>NGRAM</th>\n","      <th>RNN</th>\n","      <th>CFG</th>\n","      <th>phonemes</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Alice</td>\n","      <td>1</td>\n","      <td>0.046000</td>\n","      <td>0.608721</td>\n","      <td>1</td>\n","      <td>8.65</td>\n","      <td>0.00</td>\n","      <td>14.56</td>\n","      <td>3.620000e-07</td>\n","      <td>0.562721</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1.0</td>\n","      <td>3.226499</td>\n","      <td>3.126175</td>\n","      <td>2.312348</td>\n","      <td>['AE1', 'L', 'IH0', 'S']</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>was</td>\n","      <td>1</td>\n","      <td>0.562721</td>\n","      <td>0.830543</td>\n","      <td>2</td>\n","      <td>14.56</td>\n","      <td>8.65</td>\n","      <td>10.69</td>\n","      <td>3.840000e-09</td>\n","      <td>0.267822</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0.0</td>\n","      <td>0.905229</td>\n","      <td>1.691128</td>\n","      <td>1.357460</td>\n","      <td>['W', 'AH0', 'Z']</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>beginning</td>\n","      <td>1</td>\n","      <td>0.784543</td>\n","      <td>1.302929</td>\n","      <td>3</td>\n","      <td>10.69</td>\n","      <td>14.56</td>\n","      <td>16.35</td>\n","      <td>3.690000e-09</td>\n","      <td>0.518386</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1.0</td>\n","      <td>4.446766</td>\n","      <td>4.100771</td>\n","      <td>5.626722</td>\n","      <td>['B', 'IH0', 'G', 'IH1', 'N', 'IH0', 'NG']</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>to</td>\n","      <td>1</td>\n","      <td>1.256929</td>\n","      <td>1.398925</td>\n","      <td>4</td>\n","      <td>16.35</td>\n","      <td>10.69</td>\n","      <td>13.79</td>\n","      <td>3.970000e-09</td>\n","      <td>0.141996</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>0.0</td>\n","      <td>2.537495</td>\n","      <td>3.833313</td>\n","      <td>5.939201</td>\n","      <td>['T', 'AH0']</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>get</td>\n","      <td>1</td>\n","      <td>1.352925</td>\n","      <td>1.662327</td>\n","      <td>5</td>\n","      <td>13.79</td>\n","      <td>16.35</td>\n","      <td>13.28</td>\n","      <td>3.770000e-09</td>\n","      <td>0.309402</td>\n","      <td>5</td>\n","      <td>1</td>\n","      <td>0.0</td>\n","      <td>1.023137</td>\n","      <td>1.013076</td>\n","      <td>2.697304</td>\n","      <td>['G', 'IH1', 'T']</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c3352378-c8ca-4b71-b13b-d50e17b4e9a0')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-c3352378-c8ca-4b71-b13b-d50e17b4e9a0 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-c3352378-c8ca-4b71-b13b-d50e17b4e9a0');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-b1e7a95a-1992-40d5-9bc6-51b76142aaa2\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b1e7a95a-1992-40d5-9bc6-51b76142aaa2')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-b1e7a95a-1992-40d5-9bc6-51b76142aaa2 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","execution_count":null,"id":"3b849d1b","metadata":{"id":"3b849d1b"},"outputs":[],"source":["# DATA_DIR    = \"drive/MyDrive/brennan data/S01\" # TODO: Path where you have downloaded the data\n","\n","# mne_raw = mne.io.read_raw_brainvision(os.path.join(DATA_DIR, \"S01.vhdr\"),\n","                                      # misc=['ECG', 'EMG', 'FootPad'],preload=True)"]},{"cell_type":"code","source":["# You'll notice in the dataframe that they've timestamped each word with regard to\n","# the segmented file! That was very nice of them. Let's extract the word onset/offset\n","import numpy as np\n","segment_onset_offset = []\n","for seg_val in np.unique(data_csv[\"Segment\"].values):\n","  seg = data_csv.loc[data_csv.Segment == seg_val]\n","  onsets = seg[\"onset\"].values\n","  offsets = seg[\"offset\"].values\n","  # Append to onset/offset times\n","  segment_onset_offset.append(list(zip(onsets, offsets)))\n"],"metadata":{"id":"pHa6hIpfeEps"},"id":"pHa6hIpfeEps","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Now its time to load in the EEG data\n","# For this, we have to loop through all the subjects (49) and extract\n","# each word based on the segment and timestamp\n","import mne\n","import glob\n","from collections import Counter\n","\n","if wannaSpendForeverMakingDataAgain:\n","\n","  vhdr_files = glob.glob(\"drive/MyDrive/brennan data/*/*.vhdr\")\n","\n","  vhdr_files\n","\n","  eeg_data_list = []\n","  labels_list = []\n","\n","\n","  def data_sorter(data_string):\n","      try:\n","          return int(data_string.split(r\"/\")[-1])\n","      except:\n","          # handle division by zero error\n","          # leave empty for now\n","          return 0\n","\n","  for vhdr_file in vhdr_files[26:]:\n","\n","    # Step 1: Load the file\n","    mne_raw = mne.io.read_raw_brainvision(vhdr_file, misc=['ECG', 'EMG', 'FootPad'],preload=True)\n","\n","\n","    # A couple of the subjects have a different number of channels.\n","    # As someone who does EEG data research, I get it.\n","    # As someone doing this class project, I hate them.\n","    # Let's just ignore those people with different cap sizes to simplify things\n","    if mne_raw.get_data().shape[0] == 62:\n","\n","      # Step 2: Preprocess the filter\n","      # Note: This is very minimal, but we might not want to do too much more\n","\n","      # Bandpass filter 0.5 - 40 Hz\n","      mne_raw = mne_raw.filter(0.5, 40);\n","\n","      # Common Average Reference\n","      mne_raw.set_eeg_reference('average', projection=False);\n","\n","      # Resampling to 100 Hz is done AFTER segmentation into words to not lose\n","      # time resolution when cropping (see: .resample(100) below)\n","\n","      # Step 3: Segment into the 12 time-stamped segments\n","      # For some reason, some of the dataset first stimulus is called \"stimulus 1\"\n","      # and other times is new segment -.- . Also, calling events from annotations\n","      # can return the list in unsorted order, which will completely mess up the\n","      # whole labels to eeg alignment we have going on.\n","      # So,\n","      # mne_events, ev_id = mne.events_from_annotations(\n","      #           raw=mne_raw, event_id={\"Stimulus/{:d}\".format(i): i for i in range(0,13)})\n","\n","      mne_events, ev_id = mne.events_from_annotations(raw=mne_raw, event_id=Counter(mne_raw.annotations.description))\n","      # because strings are weird, this actually returns the events out of order.\n","      # so, let's sort them according to their timestamp. Easy peasy!\n","      mne_events = sorted(mne_events, key = lambda x: x[0])\n","\n","      if len(mne_events) > 12:\n","        # Only keep last 12 if there was an extra starting stimulus,\n","        # Otherwise, consider the starting stimulus as start of sequence\n","        mne_events = mne_events[-12:]\n","\n","      # We're just going to crop at onset time. This is because the eeg timestamps sometimes overlap\n","      # into the next segment. *eye roll*\n","      segments = [mne_raw.copy().crop(mne_events[i][0] * 1/mne_raw.info['sfreq'], None) for i in range(len(mne_events))]\n","\n","      # Step 4: Further break down each segment into the individual words\n","      for i in range(len(segments)): # there should be 12extracted_sentences = [sentences[0].copy().crop(timestamps[i], timestamps[i+1]) for i in range(len(timestamps) - 1)]\n","        #print(\"Segment: \", i)\n","        extracted_words = [segments[i].copy().crop(segment_onset_offset[i][j][0], segment_onset_offset[i][j][1]).resample(100) for j in range(len(segment_onset_offset[i]))]\n","        eeg_data_list.extend(extracted_words)\n","        #print(eeg_data_list)\n"],"metadata":{"id":"CCsWkoVZdEtM"},"id":"CCsWkoVZdEtM","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# All this preprocessing is taking 5ever. Let's not do this again.\n","if not wannaSpendForeverMakingDataAgain:\n","  import pickle\n","\n","  # copy the target phoneme list for n subjects\n","  #targets = phoneme_list * len(vhdr_files) # Repeat the labels for each subject\n","\n","  with open('drive/MyDrive/brennan data/IDL_project_data_1stHalf.pkl', 'rb') as fid:\n","      eeg_data_list = pickle.load(fid)\n","\n","  with open('drive/MyDrive/brennan data/IDL_project_data_targets.pkl', 'rb') as fid:\n","      phoneme_list = pickle.load(fid)"],"metadata":{"id":"Ul-BM-2-rhsO"},"id":"Ul-BM-2-rhsO","execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","#targets = data_csv['phonemes']\n","#phoneme_list = phoneme_list * len(vhdr_files) # Repeat the labels for each subject\n","\n","num_subj = int(len(eeg_data_list)/len(phoneme_list))\n","targets = [phoneme for phoneme in phoneme_list for _ in range(num_subj)]\n","print(len(targets))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FCAWNc-vskEY","outputId":"4aeee98d-1ecd-41b2-ae2a-4354d6b0f527","executionInfo":{"status":"ok","timestamp":1700237430306,"user_tz":300,"elapsed":12,"user":{"displayName":"Joshua Kosnoff","userId":"04340476596549550774"}}},"id":"FCAWNc-vskEY","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["50544\n"]}]},{"cell_type":"code","source":["eeg_data_list[0].get_data().T.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oFhfL-rB6qgc","executionInfo":{"status":"ok","timestamp":1700237430306,"user_tz":300,"elapsed":1686,"user":{"displayName":"Joshua Kosnoff","userId":"04340476596549550774"}},"outputId":"74d17a0c-ddf2-4455-8958-0aef6071f875"},"id":"oFhfL-rB6qgc","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(56, 62)"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["# split into training, testing, and validation set\n","import sklearn\n","from sklearn import model_selection\n","\n","train_val_targets, test_targets, train_val_eeg, test_eeg = sklearn.model_selection.train_test_split(targets, eeg_data_list, test_size=0.20, random_state=42) # 80/20 train-val/test split\n","train_targets, val_targets, train_eeg, val_eeg = sklearn.model_selection.train_test_split(train_val_targets, train_val_eeg, test_size=0.20, random_state=42) # 80/20 train / val split"],"metadata":{"id":"z5qo3ZKWosiW"},"id":"z5qo3ZKWosiW","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"66391693","metadata":{"id":"66391693"},"outputs":[],"source":["import torch\n","\n","class Dataset(torch.utils.data.Dataset):\n","\n","    def __init__(self, input_data, # EEG data\n","                 output_data = None, # phoneme data\n","                 mode = 'Training',\n","                 phonemes = PHONEMES,\n","                 min_length = 0,\n","                ): # Feel free to add more arguments\n","\n","        \"\"\"\n","        Input:\n","        input_data: Preprocessed EEG data of array of shape (N_samples, ), where each sample is shape (n_time, n_channels),\n","                    where n_channels is a consistent number across all samples\n","        output_data: phoneme data of read transcript shape (N_samples, ), where each sample is shape (n_phonemes)\n","\n","        \"\"\"\n","        assert mode in ['Training', 'Testing', 'Validation'], \"Error! Unrecognized Mode\"\n","\n","        if mode != \"Testing\":\n","          data_tuple = [(i, j) for i,j in zip(input_data, output_data) if i.shape[0] > min_length]\n","          input_data = [i[0] for i in data_tuple]\n","          output_data = [i[1] for i in data_tuple]\n","          print(\"Input data len: \", len(input_data))\n","          assert len(input_data) == len(output_data)\n","\n","        else:\n","          input_data = [i for i in input_data if i.shape[0] > min_length]\n","\n","\n","        self.EEG = input_data\n","        self.length = len(self.EEG)\n","        self.mode = mode\n","\n","        if mode != 'Testing':\n","            self.transcripts = []\n","            for transcript in output_data: #transcript is one word\n","                # print(transcript)\n","                transcript_list = []\n","                for phoneme in transcript:\n","                  phoneme = ''.join([i for i in phoneme if not i.isdigit()])\n","                  transcript_list.append(phonemes.index(phoneme))\n","\n","                self.transcripts.append(transcript_list)\n","        #print(self.transcripts)\n","\n","    def __len__(self):\n","        return self.length\n","\n","    def __getitem__(self, ind):\n","\n","        frames = self.EEG[int(ind)]\n","        frames = torch.FloatTensor(frames) # Convert to tensors\n","\n","        if self.mode in [\"Training\", \"Validation\"]:\n","            #labels = torch.tensor(self.transcripts, dtype=torch.long)\n","            labels    = torch.tensor(self.transcripts[ind], dtype=torch.long)\n","            return frames, labels\n","\n","        else:\n","            return frames\n","\n","    def collate_fn(self, batch):\n","        '''\n","        TODO:\n","        1.  Extract the features and labels from 'batch'\n","        2.  We will additionally need to pad both features and labels,\n","            look at pytorch's docs for pad_sequence\n","        3.  This is a good place to perform transforms, if you so wish.\n","            Performing them on batches will speed the process up a bit.\n","        4.  Return batch of features, labels, lenghts of features,\n","            and lengths of labels.\n","        '''\n","        # batch of input mfcc coefficients\n","        if self.mode in [\"Training\", \"Validation\"]:\n","            batch_EEG =  [x[0] for x in batch]\n","            lengths_EEG = [len(x[0]) for x in batch]# TODO\n","            batch_EEG_pad = pad_sequence(batch_EEG, batch_first=True, padding_value=0.0)\n","\n","            #batch_transcript = [x[0][1] for x in batch] # TODO\n","            batch_transcript = [x[1] for x in batch]\n","\n","            lengths_transcript = [len(x[1]) for x in batch] # TODO\n","            #print('lengths_transcript is ', lengths_transcript)\n","            #batch_transcript =  torch.tensor(batch_transcript)\n","\n","\n","            # Batch x Time x 62 channels\n","            batch_transcript_pad = pad_sequence(batch_transcript,\n","                                                batch_first=True,\n","                                                padding_value=0.0) # TODO\n","\n","            return batch_EEG_pad, batch_transcript_pad, torch.tensor(lengths_EEG), torch.tensor(lengths_transcript)\n","\n","        else:\n","            batch_EEG =  [x for x in batch]\n","            lengths_EEG = [len(x) for x in batch]# TODO\n","            batch_EEG_pad = pad_sequence(batch_EEG, batch_first=True, padding_value=0.0)\n","\n","            return batch_EEG_pad, torch.tensor(batch_EEG)"]},{"cell_type":"code","source":["config = {\n","    \"beam_width\" : 20,\n","    \"lr\"         : 2e-3,\n","    \"epochs\"     : 50,\n","    \"batch_size\" : 256  # Increase if your device can handle it\n","}"],"metadata":{"id":"ilN4TvITtZaR"},"id":"ilN4TvITtZaR","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Silence the logs because otherwise its just too much\n","\n","mne.set_log_level(False)\n","\n","def bandpass_filter_and_stack(mne_raw, all = True):\n","  if not all:\n","    theta = mne_raw.copy().filter(4, 8).get_data().T\n","    alpha = mne_raw.copy().filter(8, 12).get_data().T\n","    beta = mne_raw.copy().filter(12, 20).get_data().T\n","    gamma = mne_raw.copy().filter(20, 40).get_data().T\n","\n","    stacked = np.stack([theta, alpha, beta, gamma], axis = 1)\n","    return stacked\n","  else:\n","    all = mne_raw.copy().filter(0.5, 40).get_data().T\n","    return all\n","\n"],"metadata":{"id":"5FtXgDgPxovg"},"id":"5FtXgDgPxovg","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"6857e274","metadata":{"id":"6857e274","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700245009789,"user_tz":300,"elapsed":707843,"user":{"displayName":"Joshua Kosnoff","userId":"04340476596549550774"}},"outputId":"5a6413c7-3dbb-4367-b8e1-04c601b2662b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Input data len:  29416\n","Input data len:  7324\n"]}],"source":["train_data = Dataset(input_data = [bandpass_filter_and_stack(i) for i in train_eeg], # .get_data().T for i in range(0, 4)],\n","                     output_data = train_targets, mode = \"Training\", min_length = 10)\n","\n","val_data = Dataset(input_data = [bandpass_filter_and_stack(i) for i in val_eeg], # [extracted_sentences[4].get_data().T],\n","                     output_data = val_targets, mode = \"Validation\", min_length = 10)\n","\n","#test_data = Dataset(input_data = [i.get_data().T for i in test_eeg], #[extracted_sentences[4].get_data().T],\n","#                    mode = \"Testing\")\n","\n","# Do NOT forget to pass in the collate function as parameter while creating the dataloader\n","train_loader = torch.utils.data.DataLoader(\n","    dataset     = train_data,\n","    num_workers = 2, # <--- probably want to increase this :)\n","    batch_size  = config[\"batch_size\"],\n","    pin_memory  = True,\n","    shuffle     = True,\n","    collate_fn  = train_data.collate_fn\n",")\n","\n","val_loader = torch.utils.data.DataLoader(\n","    dataset     = val_data,\n","    num_workers = 2,\n","    batch_size  = config[\"batch_size\"],\n","    pin_memory  = True,\n","    shuffle     = False,\n","    collate_fn  = train_data.collate_fn\n",")\n","\n","# test_loader = torch.utils.data.DataLoader(\n","#     dataset     = test_data,\n","#     num_workers = 2,\n","#     batch_size  = 2,  # not a lot of samples . . .\n","#     pin_memory  = True,\n","#     shuffle     = False,\n","#     collate_fn  = train_data.collate_fn\n","# )"]},{"cell_type":"code","execution_count":null,"id":"d7dd3bf5","metadata":{"id":"d7dd3bf5","outputId":"5057ef9a-2a5c-4839-fcc2-8a9df545de17","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700245010934,"user_tz":300,"elapsed":1156,"user":{"displayName":"Joshua Kosnoff","userId":"04340476596549550774"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Batch size:  256\n","Train dataset samples = 29416, batches = 115\n","torch.Size([256, 83, 62]) torch.Size([256, 10]) torch.Size([256]) torch.Size([256])\n","tensor([[ 5,  8, 37,  ...,  0,  0,  0],\n","        [32,  6, 13,  ...,  0,  0,  0],\n","        [20, 15, 33,  ...,  0,  0,  0],\n","        ...,\n","        [15,  0,  0,  ...,  0,  0,  0],\n","        [20, 12, 37,  ...,  0,  0,  0],\n","        [24, 33, 39,  ...,  0,  0,  0]])\n"]}],"source":["# sanity check\n","print(\"Batch size: \", config[\"batch_size\"])\n","print(\"Train dataset samples = {}, batches = {}\".format(train_data.__len__(), len(train_loader)))\n","\n","for i, data in enumerate(train_loader):\n","    x, y, lx, ly = data\n","    print(x.shape, y.shape, lx.shape, ly.shape)\n","    print(y)\n","    break\n","\n"]},{"cell_type":"code","execution_count":null,"id":"0f6bab63","metadata":{"id":"0f6bab63"},"outputs":[],"source":["padding_value = 0.0\n","\n","class Network(nn.Module):\n","\n","    def __init__(self):\n","\n","        super(Network, self).__init__()\n","        self.kernel_size = 2\n","        self.stride = 1\n","\n","        # Adding some sort of embedding layer or feature extractor might help performance.\n","        self.embedding = nn.Conv1d(in_channels=62, out_channels=20, kernel_size=self.kernel_size, stride=self.stride)\n","\n","        # TODO : look up the documentation. You might need to pass some additional parameters.\n","        self.lstm = nn.LSTM(input_size = 20, hidden_size = 1000, num_layers = 5, bidirectional=True, dropout = 0.0, batch_first=True)\n","\n","        self.batch_norm = nn.Sequential(nn.BatchNorm1d(2000))\n","\n","        self.classification = nn.Sequential(\n","            nn.Linear(2000,512),\n","            # nn.ReLU(),\n","            # nn.Dropout(p=0.25),\n","            #nn.Linear(512,512),\n","            #nn.Dropout(p=.25),\n","            #nn.Linear(512,512),\n","            #nn.Dropout(p=.25),\n","            #nn.Linear(512,512),\n","            #nn.Dropout(p=.25),\n","            #nn.Linear(512,512),\n","            #nn.Dropout(p=.25),\n","            #nn.Linear(512,512),\n","            #nn.Dropout(p=.25),\n","            nn.Linear(512,41)\n","            #TODO: Linear layer with in_features from the lstm module above and out_features = OUT_SIZE\n","        )\n","\n","\n","        self.logSoftmax = nn.LogSoftmax(dim=2)#TODO: Apply a log softmax here. Which dimension would apply it on ?\n","\n","    def forward(self, x, lx):\n","        #TODO\n","        # The forward function takes 2 parameter inputs here. Why?\n","        # Refer to the handout for hints\n","        # print(x)\n","        # Permute before and after CNN\n","\n","        # Remove 0 padding\n","        # Probably need to rewrite code\n","        # Code taken from: https://stackoverflow.com/a/59076768\n","        valid_cols = [col_idx for col_idx, col in enumerate(torch.split(x, 1, dim=0)) if not torch.all(col == 1)]\n","        x = x[:, valid_cols, :]\n","\n","        x = torch.permute(x, (0, 2, 1))\n","        x = self.embedding(x)\n","        x = torch.permute(x, (0, 2, 1))\n","        # print(x)\n","\n","        # Output length of conv embedding layer\n","        lx = 1 + (lx - self.kernel_size)//self.stride\n","\n","        #print(lx)\n","        x = pack_padded_sequence(x, lx, batch_first=True, enforce_sorted=False)\n","\n","        x, (h_t, c_t) = self.lstm(x)\n","        x, lh = pad_packed_sequence(x, batch_first=True, padding_value=padding_value)\n","\n","        x = torch.permute(x, (0, 2, 1))\n","        x = self.batch_norm(x)\n","        x = torch.permute(x, (0, 2, 1))\n","\n","        x = self.classification(x)\n","        probs = self.logSoftmax(x)\n","\n","        return probs, lh"]},{"cell_type":"code","execution_count":null,"id":"3f77f5cf","metadata":{"id":"3f77f5cf","colab":{"base_uri":"https://localhost:8080/","height":408},"executionInfo":{"status":"error","timestamp":1700246180884,"user_tz":300,"elapsed":2338,"user":{"displayName":"Joshua Kosnoff","userId":"04340476596549550774"}},"outputId":"3d60ca20-065a-48a7-d386-7dabe52d9f16"},"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-47-54015426c102>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# x and lx come from the sanity check above :)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    987\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 989\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    990\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m     def register_backward_hook(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNNBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;31m# Resets _flat_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    662\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    985\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    986\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 987\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."]}],"source":["torch.cuda.empty_cache()\n","\n","model = Network().to(device)\n","summary(model, x.to(device), lx) # x and lx come from the sanity check above :)\n","model = Network().to(device)"]},{"cell_type":"code","execution_count":null,"id":"7c78fb71","metadata":{"id":"7c78fb71"},"outputs":[],"source":["#TODO\n","\n","criterion = torch.nn.CTCLoss() # Define CTC loss as the criterion. How would the losses be reduced?\n","# CTC Loss: https://pytorch.org/docs/stable/generated/torch.nn.CTCLoss.html\n","# Refer to the handout for hints\n","\n","optimizer =  torch.optim.Adam(model.parameters(), lr=0.001) # What goes in here?\n","\n","# Declare the decoder. Use the CTC Beam Decoder to decode phonemes\n","# CTC Beam Decoder Doc: https://github.com/parlance/ctcdecode\n","\n","# CTC Decoder is broke.\n","\n","# decoder = ctcdecode.CTCBeamDecoder(\n","#     LABELS,\n","#     model_path=None,\n","#     alpha=0,\n","#     beta=0,\n","#     cutoff_top_n=40,\n","#     cutoff_prob=1.0,\n","#     beam_width=20,\n","#     num_processes=4,\n","#     blank_id=0,\n","#     log_probs_input=True)\n","\n","# decoder = BeamSearchDecoder\n","decoder = ctcdecode.CTCBeamDecoder(labels=LABELS, model_path=None, alpha=0, beta=0, cutoff_top_n=40, cutoff_prob=1, beam_width=10, num_processes=4, blank_id=0, log_probs_input=True) #TODO\n","\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=2)\n","#scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=.95, last_epoch=-1)\n","\n","\n","# Mixed Precision, if you need it\n","scaler = torch.cuda.amp.GradScaler()"]},{"cell_type":"code","source":["def decode_prediction(output, output_lens, decoder, PHONEME_MAP= LABELS):\n","\n","    # TODO: look at docs for CTC.decoder and find out what is returned here. Check the shape of output and expected shape in decode.\n","    beam_results, beam_scores, timesteps, out_seq_len = decoder.decode(output, seq_lens= output_lens) #lengths - list of lengths\n","\n","    pred_strings                    = []\n","\n","    for i in range(output_lens.shape[0]):\n","        #TODO: Create the prediction from the output of decoder.decode. Don't forget to map it using PHONEMES_MAP.\n","        prediction = list(beam_results[i][0][0:out_seq_len[i][0]].cpu().numpy())\n","        predicted_string = ''.join([PHONEME_MAP[j] for j in prediction])\n","        pred_strings.append(predicted_string)\n","\n","    return pred_strings\n","\n","def calculate_levenshtein(output, label, output_lens, label_lens, decoder, PHONEME_MAP= LABELS): # y - sequence of integers\n","\n","    dist            = 0\n","    batch_size      = label.shape[0]\n","    #batch_size = len(label[0])\n","\n","    output = torch.permute(output, (1,0,2))\n","    pred_strings    = decode_prediction(output, output_lens, decoder, PHONEME_MAP)\n","    for i in range(batch_size):\n","        # TODO: Get predicted string and label string for each element in the batch\n","        pred_string = pred_strings[i]\n","        # print(\"pred before shortening: \", pred_string)\n","        label_string = label[i][0:label_lens[i]]\n","        #print('label string before replace ', label_string)\n","        label_string = ''.join([PHONEME_MAP[k] for k in label_string])\n","        print('predicted string is ', pred_string.replace(\" \", \"\"))\n","        print('label string is     ', label_string.replace(\" \", \"\"))\n","        dist += Levenshtein.distance(pred_string.replace(\" \", \"\"), label_string.replace(\" \", \"\")) #\" \" becomes \"\"\n","\n","    # Print the last things for sanity check\n","    # print('predicted string is ', pred_string.replace(\" \", \"\"))\n","    # print('label string is     ', label_string.replace(\" \", \"\"))\n","\n","    dist /= batch_size # TODO: Uncomment this, but think about why we are doing this\n","    return dist"],"metadata":{"id":"6eO_ljJ_tFyQ"},"id":"6eO_ljJ_tFyQ","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"5f3dc0a0","metadata":{"id":"5f3dc0a0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700244170117,"user_tz":300,"elapsed":4730,"user":{"displayName":"Joshua Kosnoff","userId":"04340476596549550774"}},"outputId":"13a00b67-96fe-41dc-baf1-2e7e6ab256c7"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([82, 256, 41]) torch.Size([256, 11])\n","torch.Size([256]) torch.Size([256])\n","h is  tensor([[[ -1.1009, -11.2855, -10.0301,  ...,  -9.1059,  -3.0048,  -8.8670],\n","         [ -1.0960, -11.2954, -10.0358,  ...,  -9.1161,  -3.0071,  -8.8745],\n","         [ -1.0247, -11.4249, -10.1041,  ...,  -9.2432,  -3.0461,  -8.9659],\n","         ...,\n","         [ -1.0628, -11.3543, -10.0669,  ...,  -9.1743,  -3.0243,  -8.9165],\n","         [ -1.1263, -11.2294, -10.0010,  ...,  -9.0582,  -2.9940,  -8.8221],\n","         [ -1.0810, -11.3219, -10.0499,  ...,  -9.1425,  -3.0147,  -8.8936]],\n","\n","        [[ -7.8797, -10.7662, -10.1916,  ...,  -2.5471,  -8.8134,  -2.3021],\n","         [ -7.8612, -10.7671, -10.1833,  ...,  -2.5473,  -8.8033,  -2.2989],\n","         [ -7.6283, -10.8001, -10.1074,  ...,  -2.5482,  -8.6963,  -2.2642],\n","         ...,\n","         [ -7.7524, -10.7811, -10.1483,  ...,  -2.5471,  -8.7525,  -2.2827],\n","         [ -7.9991, -10.7606, -10.2308,  ...,  -2.5552,  -8.8773,  -2.3009],\n","         [ -7.8115, -10.7729, -10.1670,  ...,  -2.5472,  -8.7797,  -2.2915]],\n","\n","        [[ -0.2916, -14.6505,  -6.3553,  ...,  -5.8978,  -4.3221,  -7.5088],\n","         [ -0.2898, -14.6731,  -6.3602,  ...,  -5.9161,  -4.3275,  -7.5233],\n","         [ -0.2577, -14.9687,  -6.5058,  ...,  -6.1558,  -4.4379,  -7.7270],\n","         ...,\n","         [ -0.2742, -14.8096,  -6.4307,  ...,  -6.0289,  -4.3787,  -7.6198],\n","         [ -0.3174, -14.4804,  -6.2456,  ...,  -5.7279,  -4.2483,  -7.2999],\n","         [ -0.2827, -14.7351,  -6.3915,  ...,  -5.9677,  -4.3501,  -7.5673]],\n","\n","        ...,\n","\n","        [[ -5.8640,  -1.2938,  -3.9341,  ...,  -5.4103,  -4.6923,  -5.6967],\n","         [ -5.8640,  -1.2938,  -3.9341,  ...,  -5.4103,  -4.6923,  -5.6967],\n","         [ -5.8640,  -1.2938,  -3.9341,  ...,  -5.4103,  -4.6923,  -5.6967],\n","         ...,\n","         [ -5.8640,  -1.2938,  -3.9341,  ...,  -5.4103,  -4.6923,  -5.6967],\n","         [ -5.8640,  -1.2938,  -3.9341,  ...,  -5.4103,  -4.6923,  -5.6967],\n","         [ -5.8640,  -1.2938,  -3.9341,  ...,  -5.4103,  -4.6923,  -5.6967]],\n","\n","        [[ -5.8640,  -1.2938,  -3.9341,  ...,  -5.4103,  -4.6923,  -5.6967],\n","         [ -5.8640,  -1.2938,  -3.9341,  ...,  -5.4103,  -4.6923,  -5.6967],\n","         [ -5.8640,  -1.2938,  -3.9341,  ...,  -5.4103,  -4.6923,  -5.6967],\n","         ...,\n","         [ -5.8640,  -1.2938,  -3.9341,  ...,  -5.4103,  -4.6923,  -5.6967],\n","         [ -5.8640,  -1.2938,  -3.9341,  ...,  -5.4103,  -4.6923,  -5.6967],\n","         [ -5.8640,  -1.2938,  -3.9341,  ...,  -5.4103,  -4.6923,  -5.6967]],\n","\n","        [[ -5.8640,  -1.2938,  -3.9341,  ...,  -5.4103,  -4.6923,  -5.6967],\n","         [ -5.8640,  -1.2938,  -3.9341,  ...,  -5.4103,  -4.6923,  -5.6967],\n","         [ -5.8640,  -1.2938,  -3.9341,  ...,  -5.4103,  -4.6923,  -5.6967],\n","         ...,\n","         [ -5.8640,  -1.2938,  -3.9341,  ...,  -5.4103,  -4.6923,  -5.6967],\n","         [ -5.8640,  -1.2938,  -3.9341,  ...,  -5.4103,  -4.6923,  -5.6967],\n","         [ -5.8640,  -1.2938,  -3.9341,  ...,  -5.4103,  -4.6923,  -5.6967]]],\n","       device='cuda:0', grad_fn=<PermuteBackward0>)\n","y is  tensor([[ 5,  8, 37,  ...,  0,  0,  0],\n","        [40, 17,  0,  ...,  0,  0,  0],\n","        [28, 33, 21,  ...,  0,  0,  0],\n","        ...,\n","        [20, 21,  0,  ...,  0,  0,  0],\n","        [ 5,  8, 37,  ...,  0,  0,  0],\n","        [29, 40,  2,  ...,  0,  0,  0]], device='cuda:0')\n","tensor(3.5187, device='cuda:0', grad_fn=<MeanBackward0>)\n","tensor(-0.0028, device='cuda:0', grad_fn=<MaxBackward1>)\n","predicted string is  A-\n","label string is      @nd\n","predicted string is  A-\n","label string is      Iz\n","predicted string is  A-\n","label string is      pleIG\n","predicted string is  A-\n","label string is      Di\n","predicted string is  A-\n","label string is      si\n","predicted string is  A-\n","label string is      Di\n","predicted string is  A-\n","label string is      @t\n","predicted string is  A-\n","label string is      fRst\n","predicted string is  A-\n","label string is      RT\n","predicted string is  A-\n","label string is      se\n","predicted string is  A-\n","label string is      hW\n","predicted string is  A-\n","label string is      @lIs\n","predicted string is  A-\n","label string is      se\n","predicted string is  A-\n","label string is      sIstR\n","predicted string is  A-\n","label string is      tA\n","predicted string is  A-\n","label string is      dipli\n","predicted string is  A-\n","label string is      R\n","predicted string is  A-\n","label string is      dozIG\n","predicted string is  A-\n","label string is      lYk\n","predicted string is  A-\n","label string is      gRl\n","predicted string is  A-\n","label string is      lAvli\n","predicted string is  A-\n","label string is      DAt\n","predicted string is  A-\n","label string is      dWn\n","predicted string is  A-\n","label string is      si\n","predicted string is  A-\n","label string is      @nd\n","predicted string is  A-\n","label string is      l@mps\n","predicted string is  A-\n","label string is      spok\n","predicted string is  A-\n","label string is      @nd\n","predicted string is  A-\n","label string is      nat\n","predicted string is  A-\n","label string is      lak\n","predicted string is  A-\n","label string is      hRsElf\n","predicted string is  A-\n","label string is      EniTIG\n","predicted string is  A-\n","label string is      DAm\n","predicted string is  A-\n","label string is      frAm\n","predicted string is  A-\n","label string is      Di\n","predicted string is  A-\n","label string is      DAt\n","predicted string is  A-\n","label string is      TIGk\n","predicted string is  A-\n","label string is      e\n","predicted string is  A-\n","label string is      tA\n","predicted string is  A-\n","label string is      hwIn\n","predicted string is  A-\n","label string is      wAz\n","predicted string is  A-\n","label string is      lYk\n","predicted string is  A-\n","label string is      Tct\n","predicted string is  A-\n","label string is      rimEmbRd\n","predicted string is  A-\n","label string is      nis\n","predicted string is  A-\n","label string is      sloli\n","predicted string is  A-\n","label string is      gat\n","predicted string is  A-\n","label string is      kcrnR\n","predicted string is  A-\n","label string is      kAt\n","predicted string is  A-\n","label string is      DEr\n","predicted string is  A-\n","label string is      tA\n","predicted string is  A-\n","label string is      hY\n","predicted string is  A-\n","label string is      @nd\n","predicted string is  A-\n","label string is      R\n","predicted string is  A-\n","label string is      mAC\n","predicted string is  A-\n","label string is      TIGk\n","predicted string is  A-\n","label string is      dWn\n","predicted string is  A-\n","label string is      vEri\n","predicted string is  A-\n","label string is      cn\n","predicted string is  A-\n","label string is      momAnt\n","predicted string is  A-\n","label string is      @ftR\n","predicted string is  A-\n","label string is      tA\n","predicted string is  A-\n","label string is      cl\n","predicted string is  A-\n","label string is      Y\n","predicted string is  A-\n","label string is      mYt\n","predicted string is  A-\n","label string is      fes\n","predicted string is  A-\n","label string is      bi\n","predicted string is  A-\n","label string is      mYnd\n","predicted string is  A-\n","label string is      It\n","predicted string is  A-\n","label string is      yu\n","predicted string is  A-\n","label string is      tebAl\n","predicted string is  A-\n","label string is      Di\n","predicted string is  A-\n","label string is      Y\n","predicted string is  A-\n","label string is      mYt\n","predicted string is  A-\n","label string is      mYAlz\n","predicted string is  A-\n","label string is      Di\n","predicted string is  A-\n","label string is      hW\n","predicted string is  A-\n","label string is      Di\n","predicted string is  A-\n","label string is      ovR\n","predicted string is  A-\n","label string is      wAz\n","predicted string is  A-\n","label string is      frR\n","predicted string is  A-\n","label string is      hcl\n","predicted string is  A-\n","label string is      Av\n","predicted string is  A-\n","label string is      larj\n","predicted string is  A-\n","label string is      cl\n","predicted string is  A-\n","label string is      dWn\n","predicted string is  A-\n","label string is      sAdAnli\n","predicted string is  A-\n","label string is      kUd\n","predicted string is  A-\n","label string is      ret\n","predicted string is  A-\n","label string is      Si\n","predicted string is  A-\n","label string is      De\n","predicted string is  A-\n","label string is      wID\n","predicted string is  A-\n","label string is      Tct\n","predicted string is  A-\n","label string is      e\n","predicted string is  A-\n","label string is      frR\n","predicted string is  A-\n","label string is      Y\n","predicted string is  A-\n","label string is      pYn@pAl\n","predicted string is  A-\n","label string is      sEvRAl\n","predicted string is  A-\n","label string is      stIks\n","predicted string is  A-\n","label string is      nEvR\n","predicted string is  A-\n","label string is      dId\n","predicted string is  A-\n","label string is      Wt\n","predicted string is  A-\n","label string is      cn\n","predicted string is  A-\n","label string is      hwIn\n","predicted string is  A-\n","label string is      Di\n","predicted string is  A-\n","label string is      hAG\n","predicted string is  A-\n","label string is      fWnd\n","predicted string is  A-\n","label string is      yuZAli\n","predicted string is  A-\n","label string is      stIks\n","predicted string is  A-\n","label string is      wak\n","predicted string is  A-\n","label string is      Si\n","predicted string is  A-\n","label string is      slipi\n","predicted string is  A-\n","label string is      DAt\n","predicted string is  A-\n","label string is      simd\n","predicted string is  A-\n","label string is      lcGd\n","predicted string is  A-\n","label string is      frR\n","predicted string is  A-\n","label string is      TIGk\n","predicted string is  A-\n","label string is      so\n","predicted string is  A-\n","label string is      mi\n","predicted string is  A-\n","label string is      wRdz\n","predicted string is  A-\n","label string is      on\n","predicted string is  A-\n","label string is      wEnt\n","predicted string is  A-\n","label string is      pritEndIG\n","predicted string is  A-\n","label string is      dId\n","predicted string is  A-\n","label string is      e\n","predicted string is  A-\n","label string is      Si\n","predicted string is  A-\n","label string is      itAn\n","predicted string is  A-\n","label string is      fil\n","predicted string is  A-\n","label string is      Di\n","predicted string is  A-\n","label string is      Av\n","predicted string is  A-\n","label string is      wID\n","predicted string is  A-\n","label string is      fWntAnz\n","predicted string is  A-\n","label string is      e\n","predicted string is  A-\n","label string is      pRsAn\n","predicted string is  A-\n","label string is      gIt\n","predicted string is  A-\n","label string is      wAn\n","predicted string is  A-\n","label string is      yu\n","predicted string is  A-\n","label string is      hEdz\n","predicted string is  A-\n","label string is      Av\n","predicted string is  A-\n","label string is      hWEvR\n","predicted string is  A-\n","label string is      nat\n","predicted string is  A-\n","label string is      fWnd\n","predicted string is  A-\n","label string is      trYd\n","predicted string is  A-\n","label string is      @t\n","predicted string is  A-\n","label string is      Y\n","predicted string is  A-\n","label string is      salAd\n","predicted string is  A-\n","label string is      fAni\n","predicted string is  A-\n","label string is      vEri\n","predicted string is  A-\n","label string is      sAm\n","predicted string is  A-\n","label string is      DAt\n","predicted string is  A-\n","label string is      e\n","predicted string is  A-\n","label string is      wRdz\n","predicted string is  A-\n","label string is      AbWt\n","predicted string is  A-\n","label string is      mAC\n","predicted string is  A-\n","label string is      fRst\n","predicted string is  A-\n","label string is      fYndIG\n","predicted string is  A-\n","label string is      nATIG\n","predicted string is  A-\n","label string is      sYz\n","predicted string is  A-\n","label string is      e\n","predicted string is  A-\n","label string is      wAn\n","predicted string is  A-\n","label string is      Y\n","predicted string is  A-\n","label string is      momAnt\n","predicted string is  A-\n","label string is      wAz\n","predicted string is  A-\n","label string is      DEr\n","predicted string is  A-\n","label string is      lYk\n","predicted string is  A-\n","label string is      mYt\n","predicted string is  A-\n","label string is      e\n","predicted string is  A-\n","label string is      fIr\n","predicted string is  A-\n","label string is      kcrnR\n","predicted string is  A-\n","label string is      h@nd\n","predicted string is  A-\n","label string is      Av\n","predicted string is  A-\n","label string is      sEvRAl\n","predicted string is  A-\n","label string is      it\n","predicted string is  A-\n","label string is      tUnYt\n","predicted string is  A-\n","label string is      TIGk\n","predicted string is  A-\n","label string is      wAz\n","predicted string is  A-\n","label string is      cn\n","predicted string is  A-\n","label string is      dIstAns\n","predicted string is  A-\n","label string is      yu\n","predicted string is  A-\n","label string is      gardAn\n","predicted string is  A-\n","label string is      Av\n","predicted string is  A-\n","label string is      wR\n","predicted string is  A-\n","label string is      bi\n","predicted string is  A-\n","label string is      lUkt\n","predicted string is  A-\n","label string is      Di\n","predicted string is  A-\n","label string is      dWn\n","predicted string is  A-\n","label string is      fcrgatAn\n","predicted string is  A-\n","label string is      TWzAn\n","predicted string is  A-\n","label string is      gIt\n","predicted string is  A-\n","label string is      mYAlz\n","predicted string is  A-\n","label string is      e\n","predicted string is  A-\n","label string is      fit\n","predicted string is  A-\n","label string is      AdvYs\n","predicted string is  A-\n","label string is      hir\n","predicted string is  A-\n","label string is      Di\n","predicted string is  A-\n","label string is      e\n","predicted string is  A-\n","label string is      tYm\n","predicted string is  A-\n","label string is      mi\n","predicted string is  A-\n","label string is      s@dli\n","predicted string is  A-\n","label string is      Y\n","predicted string is  A-\n","label string is      e\n","predicted string is  A-\n","label string is      wUd\n","predicted string is  A-\n","label string is      we\n","predicted string is  A-\n","label string is      YDR\n","predicted string is  A-\n","label string is      wIDWt\n","predicted string is  A-\n","label string is      Ap\n","predicted string is  A\n","label string is      Di\n","predicted string is  A-\n","label string is      Av\n","predicted string is  A-\n","label string is      Si\n","predicted string is  A-\n","label string is      dIlYt\n","predicted string is  A-\n","label string is      Di\n","predicted string is  A-\n","label string is      e\n","predicted string is  A-\n","label string is      mYAlz\n","predicted string is  A-\n","label string is      hW\n","predicted string is  A-\n","label string is      wUd\n","predicted string is  A-\n","label string is      momAnt\n","predicted string is  A-\n","label string is      trYd\n","predicted string is  A-\n","label string is      Si\n","predicted string is  A-\n","label string is      stupId\n","predicted string is  A-\n","label string is      hAG\n","predicted string is  A-\n","label string is      brIG\n","predicted string is  A-\n","label string is      pepR\n","predicted string is  A-\n","label string is      e\n","predicted string is  A-\n","label string is      wAz\n","predicted string is  A-\n","label string is      baks\n","predicted string is  A-\n","label string is      lEsAnz\n","predicted string is  A-\n","label string is      nEvR\n","predicted string is  A-\n","label string is      Si\n","predicted string is  A-\n","label string is      Si\n","predicted string is  A-\n","label string is      mYt\n","predicted string is  A-\n","label string is      kAn\n","predicted string is  A-\n","label string is      AndR\n","predicted string is  A-\n","label string is      du\n","predicted string is  A-\n","label string is      kanvRseSAnz\n","predicted string is  A-\n","label string is      Si\n","predicted string is  A-\n","label string is      bY\n","predicted string is  A-\n","label string is      wID\n","predicted string is  A-\n","label string is      Si\n","predicted string is  A-\n","label string is      Av\n","predicted string is  A-\n","label string is      SAtIG\n","predicted string is  A-\n","label string is      e\n","predicted string is  A-\n","label string is      Cen\n","predicted string is  A-\n","label string is      Di\n","predicted string is  A-\n","label string is      Ap\n","predicted string is  A-\n","label string is      mi\n","predicted string is  A-\n","label string is      smcl\n","predicted string is  A-\n","label string is      ret\n","predicted string is  A-\n","label string is      mi\n","predicted string is  A-\n","label string is      nat\n","predicted string is  A-\n","label string is      bAt\n","predicted string is  A-\n","label string is      @nd\n","predicted string is  A-\n","label string is      baks\n","predicted string is  A-\n","label string is      Y\n","predicted string is  A-\n","label string is      we\n","predicted string is  A-\n","label string is      @nd\n","predicted string is  A-\n","label string is      TIGz\n","3.06640625\n"]}],"source":["# test code to check shapes\n","\n","model.eval()\n","for i, data in enumerate(val_loader, 0):\n","    x, y, lx, ly = data\n","    x, y = x.to(device), y.to(device)\n","    h, lh = model(x, lx)\n","    h = torch.permute(h, (1, 0, 2))\n","    print(h.shape, y.shape)\n","    print(lh.shape, lh.shape)\n","    print('h is ', h)\n","    print('y is ', y)\n","    loss = criterion(h, y, lh, ly)\n","    print(loss)\n","    #print('ly is ', ly)\n","    print(h.max())\n","    print(calculate_levenshtein(h, y, lx, ly, decoder, LABELS))\n","\n","    break"]},{"cell_type":"markdown","id":"c28ba3ca","metadata":{"id":"c28ba3ca"},"source":["EEG to phonemes\n","\n","input EEG --> output phoneme\n","\n","EEG = (12 * N_subjects,) varying length\n","\n","\"labels\" = list (12 * N_subjects,) varying length\n","\n","\n","Follow HW3P2 logic\n","\n","Padpacked sequence whatever dataloader"]},{"cell_type":"code","source":["import wandb\n","wandb.login(key=\"dd406b9c9216ffc7053f08e284381c34b4b95df6\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RBeBTJj-sghv","outputId":"b4b8cf35-72d8-4fe5-f410-cbd1a0923c4d","executionInfo":{"status":"ok","timestamp":1700238584034,"user_tz":300,"elapsed":4675,"user":{"displayName":"Joshua Kosnoff","userId":"04340476596549550774"}}},"id":"RBeBTJj-sghv","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["run = wandb.init(\n","    name = \"alpha_band_filtered\", ## Wandb creates random run names if you skip this field\n","    reinit = True, ### Allows reinitalizing runs when you re-run this cell\n","    # run_id = ### Insert specific run id here if you want to resume a previous run\n","    # resume = \"must\" ### You need this to resume previous runs, but comment out reinit = True when using this\n","    project = \"IDL_group_project\", ### Project should be created in your wandb account\n","    config = config ### Wandb Config for your run\n",")"],"metadata":{"id":"Aw1BG-EzshMj","colab":{"base_uri":"https://localhost:8080/","height":115},"executionInfo":{"status":"ok","timestamp":1700238586429,"user_tz":300,"elapsed":2407,"user":{"displayName":"Joshua Kosnoff","userId":"04340476596549550774"}},"outputId":"252f4c14-c8d3-46f9-893f-b5901165aca7"},"id":"Aw1BG-EzshMj","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjkosnoff\u001b[0m (\u001b[33midl-f23-bestteam\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.16.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20231117_162943-tlmptipy</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/idl-f23-bestteam/IDL_group_project/runs/tlmptipy' target=\"_blank\">alpha_band_filtered</a></strong> to <a href='https://wandb.ai/idl-f23-bestteam/IDL_group_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/idl-f23-bestteam/IDL_group_project' target=\"_blank\">https://wandb.ai/idl-f23-bestteam/IDL_group_project</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/idl-f23-bestteam/IDL_group_project/runs/tlmptipy' target=\"_blank\">https://wandb.ai/idl-f23-bestteam/IDL_group_project/runs/tlmptipy</a>"]},"metadata":{}}]},{"cell_type":"code","source":["# from tqdm import tqdm\n","\n","# def train_model(model, train_loader, criterion, optimizer):\n","\n","#     model.train()\n","#     batch_bar = tqdm(total=len(train_loader), dynamic_ncols=True, leave=False, position=0, desc='Train')\n","\n","#     total_loss = 0\n","\n","#     for i, data in enumerate(train_loader):\n","#         optimizer.zero_grad()\n","\n","#         x, y, lx, ly = data\n","#         x, y = x.to(device), y.to(device)\n","\n","#         with torch.cuda.amp.autocast():\n","#             h, lh = model(x, lx)\n","#             h = torch.permute(h, (1, 0, 2))\n","#             loss = criterion(h, y, lh, ly)\n","\n","#         total_loss += loss.item()\n","\n","#         batch_bar.set_postfix(\n","#             loss=\"{:.04f}\".format(float(total_loss / (i + 1))),\n","#             lr=\"{:.06f}\".format(float(optimizer.param_groups[0]['lr'])))\n","\n","#         batch_bar.update() # Update tqdm bar\n","\n","#         # Another couple things you need for FP16.\n","#         scaler.scale(loss).backward() # This is a replacement for loss.backward()\n","#         scaler.step(optimizer) # This is a replacement for optimizer.step()\n","#         scaler.update() # This is something added just for FP16\n","\n","#         del x, y, lx, ly, h, lh, loss\n","#         torch.cuda.empty_cache()\n","\n","#     batch_bar.close() # You need this to close the tqdm bar\n","\n","#     return total_loss / len(train_loader)\n","\n","\n","# def validate_model(model, val_loader, decoder, phoneme_map= LABELS):\n","\n","#     model.eval()\n","#     batch_bar = tqdm(total=len(val_loader), dynamic_ncols=True, position=0, leave=False, desc='Val')\n","\n","#     total_loss = 0\n","#     vdist = 0\n","\n","#     for i, data in enumerate(val_loader):\n","\n","#         x, y, lx, ly = data\n","#         x, y = x.to(device), y.to(device)\n","\n","#         with torch.inference_mode():\n","#             h, lh = model(x, lx)\n","#             h = torch.permute(h, (1, 0, 2))\n","#             loss = criterion(h, y, lh, ly)\n","\n","#         total_loss += float(loss)\n","#         vdist += calculate_levenshtein(torch.permute(h, (1, 0, 2)), y, lh, ly, decoder, phoneme_map)\n","\n","#         batch_bar.set_postfix(loss=\"{:.04f}\".format(float(total_loss / (i + 1))), dist=\"{:.04f}\".format(float(vdist / (i + 1))))\n","\n","#         batch_bar.update()\n","\n","#         del x, y, lx, ly, h, lh, loss\n","#         torch.cuda.empty_cache()\n","\n","#     batch_bar.close()\n","#     total_loss = total_loss/len(val_loader)\n","#     val_dist = vdist/len(val_loader)\n","#     return total_loss, val_dist"],"metadata":{"id":"5ngLM4OgsMvf"},"id":"5ngLM4OgsMvf","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def save_model(model, optimizer, scheduler, metric, epoch, path):\n","    torch.save(\n","        {'model_state_dict'         : model.state_dict(),\n","         'optimizer_state_dict'     : optimizer.state_dict(),\n","         'scheduler_state_dict'     : scheduler.state_dict(),\n","         metric[0]                  : metric[1],\n","         'epoch'                    : epoch},\n","         path\n","    )\n","\n","def load_model(path, model, metric= 'valid_acc', optimizer= None, scheduler= None):\n","\n","    checkpoint = torch.load(path)\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","\n","    if optimizer != None:\n","        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","    if scheduler != None:\n","        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n","\n","    epoch   = checkpoint['epoch']\n","    metric  = checkpoint[metric]\n","\n","    return [model, optimizer, scheduler, epoch, metric]"],"metadata":{"id":"Lat8-G4_sRka"},"id":"Lat8-G4_sRka","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# This is for checkpointing, if you're doing it over multiple sessions\n","\n","last_epoch_completed = 0\n","start = last_epoch_completed\n","end = config[\"epochs\"]\n","best_lev_dist = float(\"inf\") # if you're restarting from some checkpoint, use what you saw there.\n","#epoch_model_path = #TODO set the model path( Optional, you can just store best one. Make sure to make the changes below )\n","best_model_path = 'checkpoint.pth' #TODO set best model path"],"metadata":{"id":"jmEMr37ZsSY1"},"id":"jmEMr37ZsSY1","execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tqdm import tqdm\n","\n","def train(model, train_loader, criterion, optimizer):\n","\n","    model.train()\n","    batch_bar = tqdm(total=len(train_loader), dynamic_ncols=True, leave=False, position=0, desc='Train')\n","\n","    total_loss = 0\n","\n","    for i, data in enumerate(train_loader):\n","        optimizer.zero_grad()\n","\n","        x, y, lx, ly = data\n","        x, y = x.to(device), y.to(device)\n","\n","        # with torch.cuda.amp.autocast():\n","        h, lh = model(x, lx)\n","        h = torch.permute(h, (1, 0, 2))\n","        loss = criterion(h, y, lh, ly)\n","\n","        # print(h, y)\n","        # print(lh, ly)\n","        # print(loss)\n","        total_loss += loss.item() if (not np.isnan(loss.item())) and (not np.isinf(loss.item())) else 10\n","\n","        batch_bar.set_postfix(\n","            loss=\"{:.04f}\".format(float(total_loss / (i + 1))),\n","            lr=\"{:.06f}\".format(float(optimizer.param_groups[0]['lr'])))\n","\n","        batch_bar.update() # Update tqdm bar\n","\n","        # Another couple things you need for FP16.\n","        scaler.scale(loss).backward() # This is a replacement for loss.backward()\n","        scaler.step(optimizer) # This is a replacement for optimizer.step()\n","\n","        # Clip gradient ?????\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 10)\n","\n","        scaler.update() # This is something added just for FP16\n","\n","        del x, y, lx, ly, h, lh, loss\n","        torch.cuda.empty_cache()\n","\n","    batch_bar.close() # You need this to close the tqdm bar\n","\n","    return total_loss / len(train_loader)\n","\n","\n","def validate(model, val_loader, decoder, phoneme_map= LABELS):\n","\n","    model.eval()\n","    batch_bar = tqdm(total=len(val_loader), dynamic_ncols=True, position=0, leave=False, desc='Val')\n","\n","    total_loss = 0\n","    vdist = 0\n","\n","    for i, data in enumerate(val_loader):\n","\n","        x, y, lx, ly = data\n","        x, y = x.to(device), y.to(device)\n","\n","        with torch.inference_mode():\n","            h, lh = model(x, lx)\n","            h = torch.permute(h, (1, 0, 2))\n","            loss = criterion(h, y, lh, ly)\n","\n","        total_loss += loss.item() if (not np.isnan(loss.item())) and (not np.isinf(loss.item())) else 999\n","        vdist += calculate_levenshtein(h, y, lh, ly, decoder, phoneme_map)\n","\n","        batch_bar.set_postfix(loss=\"{:.04f}\".format(float(total_loss / (i + 1))), dist=\"{:.04f}\".format(float(vdist / (i + 1))))\n","\n","        batch_bar.update()\n","\n","        del x, y, lx, ly, h, lh, loss\n","        torch.cuda.empty_cache()\n","\n","    batch_bar.close()\n","    total_loss = total_loss/len(val_loader)\n","    val_dist = vdist/len(val_loader)\n","    return total_loss, val_dist"],"metadata":{"id":"H4w7yRrasVrs"},"id":"H4w7yRrasVrs","execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.cuda.empty_cache()\n","gc.collect()\n","best_lev_dist = 100\n","#TODO: Please complete the training loop\n","\n","for epoch in range(0, config['epochs']):\n","\n","    print(\"\\nEpoch: {}/{}\".format(epoch+1, config['epochs']))\n","\n","    curr_lr = float(optimizer.param_groups[0]['lr'])\n","    train_loss = train(model, train_loader, criterion, optimizer)\n","    valid_loss, valid_dist = validate(model, val_loader, decoder)\n","    scheduler.step(valid_loss) #needs loss to step (plateau)\n","    #scheduler.step() #does not need loss (exponential)\n","\n","    print(\"\\tTrain Loss {:.04f}\\t Learning Rate {:.07f}\".format(train_loss, curr_lr))\n","    print(\"\\tVal Dist {:.04f}\\t Val Loss {:.04f}\".format(valid_dist, valid_loss))\n","\n","\n","    wandb.log({\n","        'train_loss': train_loss,\n","        'valid_dist': valid_dist,\n","        'valid_loss': valid_loss,\n","        'lr'        : curr_lr\n","    })\n","\n","    #save_model(model, optimizer, scheduler, ['valid_dist', valid_dist], epoch, epoch_model_path)\n","    #wandb.save(epoch_model_path)\n","    #print(\"Saved epoch model\")\n","\n","    if valid_dist <= best_lev_dist:\n","        best_lev_dist = valid_dist\n","        save_model(model, optimizer, scheduler, ['valid_dist', valid_dist], epoch, best_model_path)\n","        wandb.save(best_model_path)\n","        print(\"Saved best model\")\n","      # You may find it interesting to exlplore Wandb Artifcats to version your models\n","run.finish()"],"metadata":{"id":"BUu82wztsX-v","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1700244131714,"user_tz":300,"elapsed":5545290,"user":{"displayName":"Joshua Kosnoff","userId":"04340476596549550774"}},"outputId":"8ca46d00-ec03-4ea7-ad05-fad158a6f08a"},"id":"BUu82wztsX-v","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Epoch: 1/50\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\tTrain Loss 5.3006\t Learning Rate 0.0010000\n","\tVal Dist 2.9656\t Val Loss 38.2241\n","Saved best model\n","\n","Epoch: 2/50\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\tTrain Loss 3.9087\t Learning Rate 0.0010000\n","\tVal Dist 2.9568\t Val Loss 38.0138\n","Saved best model\n","\n","Epoch: 3/50\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\tTrain Loss 3.7733\t Learning Rate 0.0010000\n","\tVal Dist 3.0157\t Val Loss 38.2178\n","\n","Epoch: 4/50\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\tTrain Loss 3.7019\t Learning Rate 0.0010000\n","\tVal Dist 2.9568\t Val Loss 37.9573\n","Saved best model\n","\n","Epoch: 5/50\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\tTrain Loss 3.7118\t Learning Rate 0.0010000\n","\tVal Dist 3.0047\t Val Loss 37.9011\n","\n","Epoch: 6/50\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\tTrain Loss 3.7161\t Learning Rate 0.0010000\n","\tVal Dist 3.0210\t Val Loss 37.9077\n","\n","Epoch: 7/50\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\tTrain Loss 3.6742\t Learning Rate 0.0010000\n","\tVal Dist 3.0047\t Val Loss 37.8773\n","\n","Epoch: 8/50\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\tTrain Loss 3.6388\t Learning Rate 0.0010000\n","\tVal Dist 3.0047\t Val Loss 37.9553\n","\n","Epoch: 9/50\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\tTrain Loss 3.6923\t Learning Rate 0.0010000\n","\tVal Dist 3.0112\t Val Loss 38.1919\n","\n","Epoch: 10/50\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\tTrain Loss 3.6522\t Learning Rate 0.0010000\n","\tVal Dist 3.0047\t Val Loss 37.8913\n","\n","Epoch: 11/50\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\tTrain Loss 3.6316\t Learning Rate 0.0005000\n","\tVal Dist 2.9568\t Val Loss 37.8573\n","Saved best model\n","\n","Epoch: 12/50\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\tTrain Loss 3.6210\t Learning Rate 0.0005000\n","\tVal Dist 2.9713\t Val Loss 37.8327\n","\n","Epoch: 13/50\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\tTrain Loss 3.6062\t Learning Rate 0.0005000\n","\tVal Dist 2.9570\t Val Loss 37.8572\n","\n","Epoch: 14/50\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\tTrain Loss 3.6156\t Learning Rate 0.0005000\n","\tVal Dist 2.9572\t Val Loss 37.8307\n","\n","Epoch: 15/50\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\tTrain Loss 3.6060\t Learning Rate 0.0005000\n","\tVal Dist 2.9568\t Val Loss 37.9216\n","Saved best model\n","\n","Epoch: 16/50\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\tTrain Loss 3.5980\t Learning Rate 0.0002500\n","\tVal Dist 2.9568\t Val Loss 37.8224\n","Saved best model\n","\n","Epoch: 17/50\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\tTrain Loss 3.5994\t Learning Rate 0.0002500\n","\tVal Dist 2.9568\t Val Loss 37.8303\n","Saved best model\n","\n","Epoch: 18/50\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\tTrain Loss 3.5841\t Learning Rate 0.0002500\n","\tVal Dist 3.0047\t Val Loss 37.8227\n","\n","Epoch: 19/50\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\tTrain Loss 3.5692\t Learning Rate 0.0002500\n","\tVal Dist 2.9789\t Val Loss 37.8207\n","\n","Epoch: 20/50\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["\tTrain Loss 3.5671\t Learning Rate 0.0001250\n","\tVal Dist 2.9567\t Val Loss 37.8148\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-32-00ad667b736d>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalid_dist\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mbest_lev_dist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mbest_lev_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_dist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'valid_dist'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dist\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Saved best model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-29-51903e297c27>\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, optimizer, scheduler, metric, epoch, path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     torch.save(\n\u001b[0m\u001b[1;32m      3\u001b[0m         {'model_state_dict'         : model.state_dict(),\n\u001b[1;32m      4\u001b[0m          \u001b[0;34m'optimizer_state_dict'\u001b[0m     \u001b[0;34m:\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m          \u001b[0;34m'scheduler_state_dict'\u001b[0m     \u001b[0;34m:\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m             \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[0;31m# Now that it is on the CPU we can directly copy it into the zip file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m         \u001b[0mnum_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m         \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_ptr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}